{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efdfc57d",
   "metadata": {},
   "source": [
    "# 01 Data Loading & Validation\n",
    "**Goal:** Load processed tables, validate schema expectations, and surface missingness.\n",
    "\n",
    "This notebook:\n",
    "- Loads the AI Incident Database snapshot\n",
    "- Normalizes schema\n",
    "- Audits coverage across taxonomies\n",
    "- Evaluates data completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0875fb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incidents: (1367, 9)\n",
      "Reports: (6687, 21)\n",
      "Submissions: (45, 15)\n",
      "MIT: (1242, 8)\n",
      "GMF: (326, 21)\n",
      "CSET: (214, 65)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATA = Path(\"../data\")\n",
    "OUT = Path(\"../outputs/figures\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "inc = pd.read_csv(DATA / \"incidents.csv\")\n",
    "rep = pd.read_csv(DATA / \"reports.csv\")\n",
    "sub = pd.read_csv(DATA / \"submissions.csv\")\n",
    "\n",
    "mit = pd.read_csv(DATA / \"classifications_MIT.csv\") if (DATA / \"classifications_MIT.csv\").exists() else None\n",
    "gmf = pd.read_csv(DATA / \"classifications_GMF.csv\") if (DATA / \"classifications_GMF.csv\").exists() else None\n",
    "cset = pd.read_csv(DATA / \"classifications_CSETv1.csv\") if (DATA / \"classifications_CSETv1.csv\").exists() else None\n",
    "\n",
    "print(\"Incidents:\", inc.shape)\n",
    "print(\"Reports:\", rep.shape)\n",
    "print(\"Submissions:\", sub.shape)\n",
    "print(\"MIT:\", None if mit is None else mit.shape)\n",
    "print(\"GMF:\", None if gmf is None else gmf.shape)\n",
    "print(\"CSET:\", None if cset is None else cset.shape)\n",
    "\n",
    "# normalize columns\n",
    "inc.columns = [c.strip().lower() for c in inc.columns]\n",
    "rep.columns = [c.strip().lower() for c in rep.columns]\n",
    "sub.columns = [c.strip().lower() for c in sub.columns]\n",
    "\n",
    "if mit is not None: mit.columns = [c.strip().lower() for c in mit.columns]\n",
    "if gmf is not None: gmf.columns = [c.strip().lower() for c in gmf.columns]\n",
    "if cset is not None: cset.columns = [c.strip().lower() for c in cset.columns]\n",
    "\n",
    "# MIT uses \"incident id\" sometimes\n",
    "if mit is not None and \"incident id\" in mit.columns:\n",
    "    mit = mit.rename(columns={\"incident id\": \"incident_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65f06b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc keys: ['_id', 'incident_id']\n",
      "rep keys: ['_id']\n",
      "sub keys: ['image_url', 'incident_date', 'incident_id', 'mongodb_id', 'url']\n",
      "mit keys: ['incident_id']\n"
     ]
    }
   ],
   "source": [
    "print(\"inc keys:\", [c for c in inc.columns if \"incident\" in c or c.endswith(\"_id\")])\n",
    "print(\"rep keys:\", [c for c in rep.columns if \"incident\" in c or c.endswith(\"_id\")])\n",
    "print(\"sub keys:\", [c for c in sub.columns if \"incident\" in c or \"url\" in c or c.endswith(\"_id\")])\n",
    "print(\"mit keys:\", [] if mit is None else [c for c in mit.columns if \"incident\" in c or c.endswith(\"_id\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "704b9254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIT incident column: incident_id\n",
      "GMF incident column: incident id\n",
      "CSET incident column: incident id\n",
      "MIT coverage:  90.9%\n",
      "GMF coverage:  23.8%\n",
      "CSET coverage: 15.7%\n",
      "Total reports (rows): 6687\n",
      "Unique report URLs: 5846\n",
      "Unique source domains: 1781\n",
      "Submissions rows (auxiliary): 45\n",
      "Note: This snapshot has no incident↔report mapping table, so per-incident report counts are not reproducible here.\n"
     ]
    }
   ],
   "source": [
    "def pick_incident_col(df, label):\n",
    "    cols = [c.strip().lower() for c in df.columns]\n",
    "    df.columns = cols\n",
    "    for cand in [\"incident_id\", \"incident id\", \"incidentid\"]:\n",
    "        if cand in cols:\n",
    "            return cand\n",
    "    for c in cols:\n",
    "        if \"incident\" in c and \"id\" in c:\n",
    "            return c\n",
    "    for c in cols:\n",
    "        if \"incident\" in c:\n",
    "            return c\n",
    "    raise KeyError(f\"[{label}] Could not find incident id column.\")\n",
    "\n",
    "incident_ids = set(inc[\"incident_id\"])\n",
    "\n",
    "mit_inc_col = pick_incident_col(mit, \"MIT\") if mit is not None else None\n",
    "gmf_inc_col = pick_incident_col(gmf, \"GMF\") if gmf is not None else None\n",
    "cset_inc_col = pick_incident_col(cset, \"CSET\") if cset is not None else None\n",
    "\n",
    "print(\"MIT incident column:\", mit_inc_col)\n",
    "print(\"GMF incident column:\", gmf_inc_col)\n",
    "print(\"CSET incident column:\", cset_inc_col)\n",
    "\n",
    "mit_cov = (mit[mit_inc_col].nunique() / len(incident_ids)) if mit is not None else 0\n",
    "gmf_cov = (gmf[gmf_inc_col].nunique() / len(incident_ids)) if gmf is not None else 0\n",
    "cset_cov = (cset[cset_inc_col].nunique() / len(incident_ids)) if cset is not None else 0\n",
    "\n",
    "print(f\"MIT coverage:  {mit_cov:.1%}\")\n",
    "print(f\"GMF coverage:  {gmf_cov:.1%}\")\n",
    "print(f\"CSET coverage: {cset_cov:.1%}\")\n",
    "\n",
    "print(\"Total reports (rows):\", len(rep))\n",
    "print(\"Unique report URLs:\", rep[\"url\"].nunique() if \"url\" in rep.columns else \"n/a\")\n",
    "print(\"Unique source domains:\", rep[\"source_domain\"].nunique() if \"source_domain\" in rep.columns else \"n/a\")\n",
    "print(\"Submissions rows (auxiliary):\", len(sub))\n",
    "print(\"Note: This snapshot has no incident↔report mapping table, so per-incident report counts are not reproducible here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49d1dc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                                        0.0\n",
       "incident_id                                0.0\n",
       "date                                       0.0\n",
       "reports                                    0.0\n",
       "alleged deployer of ai system              0.0\n",
       "alleged developer of ai system             0.0\n",
       "alleged harmed or nearly harmed parties    0.0\n",
       "description                                0.0\n",
       "title                                      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = inc.isna().mean().sort_values(ascending=False)\n",
    "missing.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e46c9f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with >50% missingness: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_missing = missing[missing > 0.5]\n",
    "print(f\"Columns with >50% missingness: {len(high_missing)}\")\n",
    "high_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a748fe7a",
   "metadata": {},
   "source": [
    "### Missingness Assessment (Incidents Table)\n",
    "\n",
    "We evaluated column-level missingness in `incidents.csv` to assess structural completeness and downstream analytical reliability.\n",
    "\n",
    "**Finding:**  \n",
    "No columns exhibit greater than 50% missingness.\n",
    "\n",
    "**Implications:**\n",
    "- The incident-level dataset is structurally complete.\n",
    "- Core identifiers and metadata fields are consistently populated.\n",
    "- Descriptive trend analysis can be conducted without major imputation.\n",
    "- Missingness is unlikely to systematically bias high-level distributional statistics.\n",
    "\n",
    "**Analytical Decision:**  \n",
    "All incident-level variables are retained for descriptive and comparative analysis. No columns are excluded due to sparsity in this snapshot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
